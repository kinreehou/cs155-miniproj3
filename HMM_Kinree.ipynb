{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import os\n",
    "from punctuation_dict import get_punctuation_dict\n",
    "from HMM_helper import *\n",
    "from HMM import unsupervised_HMM\n",
    "from syllable_dict import get_syllable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "syl_dict = get_syllable_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try learning by paragraph\n",
    "def getData(text):\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "    cap_words = [\"i'll\", 'i', 'o']\n",
    "    punc_dict = get_punctuation_dict()\n",
    "    \n",
    "    obs_counter = 0\n",
    "    obs1 = []\n",
    "    obs2 = []\n",
    "    obs_map = {}\n",
    "    obs_elem = [[],[],[],[]]\n",
    "    #line_counter = 0\n",
    "    for line in lines:\n",
    "        if len(line) == 1:\n",
    "            line_counter = 0\n",
    "            obs1+= obs_elem[:-1]\n",
    "            obs2.append(obs_elem[-1]) \n",
    "            obs_elem = [[],[],[],[]]\n",
    "            continue\n",
    "        #  4+4+4+2\n",
    "        line_counter+=1\n",
    "        \n",
    "        for word in line:\n",
    "            word = punc_dict[re.sub(r'[^\\w]', '', word.lower())]\n",
    "            #print(word)\n",
    "            \n",
    "            # Keep certain words capitalized\n",
    "            if word in cap_words:\n",
    "                word = word.capitalize()\n",
    "            \n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "                \n",
    "            obs_elem[(line_counter-1)//4].append(obs_map[word])\n",
    "            \n",
    "        \n",
    "    return obs1[3:],obs2[1:],obs_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    # Store a list of words to keep capitalized\n",
    "    cap_words = ['i', 'o']\n",
    "    punc_dict = get_punctuation_dict()\n",
    "    \n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    # Iterate through all the lines of poems\n",
    "    for line in lines:\n",
    "        # Skip line with poem id (not an actual line of poem)\n",
    "        if len(line) == 1:\n",
    "            continue\n",
    "\n",
    "        obs_elem = []\n",
    "        \n",
    "        for word in line:\n",
    "            # Convert to lowercase and remove punctuations not part of a word\n",
    "            word = punc_dict[re.sub(r'[^\\w]', '', word.lower())]\n",
    "            \n",
    "            # Keep certain words capitalized\n",
    "            if word in cap_words:\n",
    "                word = word.capitalize()\n",
    "            \n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "            \n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "        # Add the encoded sequence.\n",
    "        obs_elem_r = obs_elem[::-1]\n",
    "        obs.append(obs_elem_r)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRhymeDict(text):\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "    sonnets = []\n",
    "    sonnet = []\n",
    "    for line in lines:\n",
    "        if len(line) == 1:\n",
    "            # Only store sonnets with 14 lines\n",
    "            if len(sonnet) == 14:\n",
    "                sonnets.append(sonnet)\n",
    "            sonnet = []\n",
    "            continue\n",
    "        sonnet.append(line)\n",
    "\n",
    "    # This rhyme dictionary is a list of sets, where all the elements in each set rhyme with each other\n",
    "    rhyme_dict = []\n",
    "    punc_dict = get_punctuation_dict()\n",
    "    cap_words = [\"i'll\", 'i', 'o']\n",
    "\n",
    "    def process_word(word):\n",
    "        '''\n",
    "        This function takes as its input a word and returns the processed word by \n",
    "        getting rid of unnecessary punctuations / capitalizations. \n",
    "        ''' \n",
    "        # Exception \"I'll\" - confusion with ill should be manually taken care of\n",
    "        if word == \"I'll\":\n",
    "            return word \n",
    "        # Convert to lowercase and remove punctuations not part of a word\n",
    "        word = punc_dict[re.sub(r'[^\\w]', '', word.lower())]\n",
    "\n",
    "        # Keep certain words capitalized\n",
    "        if word in cap_words:\n",
    "            word = word.capitalize()\n",
    "        return word\n",
    "    \n",
    "    def add_to_rhyme_dict(w1, w2):\n",
    "        group_contain_w1 = None\n",
    "        group_contain_w2 = None\n",
    "        for group in rhyme_dict:\n",
    "            if w1 in group:\n",
    "                group_contain_w1=group\n",
    "                rhyme_dict.remove(group)\n",
    "            continue\n",
    "            if w2 in group:\n",
    "                group_contain_w2=group\n",
    "                rhyme_dict.remove(group)\n",
    "\n",
    "        if not (group_contain_w1 or group_contain_w2):\n",
    "            rhyme_dict.append({w1, w2})\n",
    "        elif not group_contain_w1:\n",
    "            group_contain_w2.add(w1)\n",
    "            rhyme_dict.append(group_contain_w2)\n",
    "        elif not group_contain_w2:\n",
    "            group_contain_w1.add(w2)\n",
    "            rhyme_dict.append(group_contain_w1)\n",
    "        else:\n",
    "            group_contain_w2.update(group_contain_w1)\n",
    "            rhyme_dict.append(group_contain_w1)\n",
    "\n",
    "    for sonnet in sonnets:\n",
    "        # Get all the rhyming pairs in the first 3 stanzas\n",
    "        for i in [0, 1, 4, 5, 8, 9]:\n",
    "            word1 = process_word(sonnet[i][-1])\n",
    "            word2 = process_word(sonnet[i+2][-1])\n",
    "            add_to_rhyme_dict(word1, word2)\n",
    "        # Last two rows of a sonnet rhyme\n",
    "        add_to_rhyme_dict(process_word(sonnet[12][-1]), process_word(sonnet[13][-1]))\n",
    "        \n",
    "    rhyme_dict = [list(x) for x in rhyme_dict]\n",
    "    return rhyme_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Iteration: 20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "Iteration: 30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "Iteration: 40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "Iteration: 50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "Iteration: 60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "Iteration: 70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "Iteration: 80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "Iteration: 90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "Iteration: 100\n"
     ]
    }
   ],
   "source": [
    "obs, obs_map = parse_observations(text)\n",
    "hmm = unsupervised_HMM(obs, 2, 100)\n",
    "#print(obs_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneSentence(hmm, obs_map,n_syl=10):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    emission = hmm.generate_emission(n_syl,obs_map_r, syl_dict)[0]\n",
    "    sentence = [obs_map_r[i] for i in emission][::-1]\n",
    "    sentence[0] = sentence[0].capitalize()\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneSentence_rhyme(hmm, obs_map, start_word, n_syl=10):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    start_state = hmm.find_state(obs_map[start_word])\n",
    "    \n",
    "    emission = hmm.generate_emission_with_start(n_syl,obs_map, obs_map_r,syl_dict,start_word, start_state)[0]\n",
    "    sentence = [obs_map_r[i] for i in emission][::-1]\n",
    "    sentence[0] = sentence[0].capitalize()\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneSonnet():\n",
    "#need starting word num\n",
    "    sonnet = ''\n",
    "    \n",
    "    for _ in range(12):\n",
    "        s = geneSentence(hmm, obs_map)\n",
    "        sonnet += (s + '\\n')\n",
    "    \n",
    "    # Last stanza\n",
    "    for _ in range(2):\n",
    "        s = geneSentence(hmm, obs_map)\n",
    "        sonnet += '  ' \n",
    "        sonnet += (s  + '\\n')\n",
    "\n",
    "    print(sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneSonnet_rhyme(ryhme_dict):\n",
    "#need starting word num\n",
    "    sonnet = ''\n",
    "    ryhme_wordpair = []\n",
    "    for _ in range(7):\n",
    "        curr_group = random.choice(ryhme_dict)\n",
    "        ryhme_wordpair.append(random.sample(curr_group, 2))\n",
    "    print(ryhme_wordpair)\n",
    "    \n",
    "    for stanza in range(3):\n",
    "        s1 = geneSentence_rhyme(hmm, obs_map, ryhme_wordpair[2*stanza][0])\n",
    "        s3 = geneSentence_rhyme(hmm, obs_map, ryhme_wordpair[2*stanza][1])\n",
    "        s2 = geneSentence_rhyme(hmm, obs_map, ryhme_wordpair[2*stanza+1][0])\n",
    "        s4 = geneSentence_rhyme(hmm, obs_map, ryhme_wordpair[2*stanza+1][1])\n",
    "        \n",
    "        sonnet += (s1  + '\\n' + s2 + '\\n' + s3 + '\\n' + s4 +'\\n')\n",
    "    \n",
    "    # Last stanza\n",
    "    s1 = geneSentence_rhyme(hmm, obs_map, ryhme_wordpair[-1][0])\n",
    "    s2 = geneSentence_rhyme(hmm, obs_map, ryhme_wordpair[-1][1])\n",
    "        \n",
    "    sonnet += '  ' + s1 + '\\n  ' + s2 + '\\n' \n",
    "    print(sonnet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So had love nature's he my choirs dry help\n",
      "Dost thy this of by his dressed from mounted\n",
      "Fortune call monument my pitying more\n",
      "Make thy loves left with thou that for yet mind\n",
      "Sad this and since and millions times a doth\n",
      "Be though a a cherubins evident\n",
      "Eyes shadow that thou of were where that bare\n",
      "Reason dear them thy is onwards hand all\n",
      "See what more dost shalt have if bear the thee\n",
      "These as catch in string thee I one that true\n",
      "Acquaintance none thy poor blood love will she\n",
      "Him worth less more audit hath why by canst\n",
      "  The drooping purity may memory\n",
      "  Or I thy from wilt they which live painted\n",
      "\n",
      "[['dispense', 'commence'], ['muse', 'use'], ['cherish', 'perish'], ['rehearse', 'inhearse'], ['register', 'character'], ['sadly', 'gladly'], ['purge', 'urge']]\n",
      "Me seeing foul that nor by plight dispense\n",
      "Counterpart lease my to is believe muse\n",
      "Give on where it heart marble sun commence\n",
      "Thou gives accuse in I what read me use\n",
      "Though if violet look brought light cherish\n",
      "Many all water crow find head rehearse\n",
      "Barren and most summer lov'st chase perish\n",
      "Of more my to on yet not dead inhearse\n",
      "Thou of nor all my they ill register\n",
      "Doth will pent sourest my hast state sadly\n",
      "Not rest say this thou lend not character\n",
      "Who or thyself I if is time gladly\n",
      "  Poets drink ill rude princes increase purge\n",
      "  What map winter and come and in cease urge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ryhme_dict = getRhymeDict(text)\n",
    "geneSonnet()\n",
    "geneSonnet_rhyme(ryhme_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
